\section{Лекция номер 13}

\subsection{Нормальные операторы в евклидовом пространстве}

Вспомним, что по любому пространству $V / \R$ мы можем построить комплисификацию $V_{\C} / \C$, той же размерности.
Можно представлять, что $V_{\C} / \C$ состоит из векторов вида $\{ v + iw \, | \, v,w \in V \}$, где $i$ -- мнимая единица. 
Также мы знаем, что если $n$ векторов $v_1, \dots, v_n \in V$ образуют базис $V$ $\Longleftrightarrow v_1, \dots, v_n$ образуют базис $V_{\C}$. 
Заметим, что стрелочка влево есть только при условии, что наши $n$ вещественных векторов принадлежали $V$. 
Действительно, если $\alpha_1 v_1 + \dots + \alpha_n v_b = 0 \Longrightarrow \alpha_1 = \dots = \alpha_n = 0$.
Давайте условимся называть вектор с нулевой мнимой частью вещественным вектором: $v + i \cdot 0 = v$. Тогда, строго говоря, 
наш базис $v_1, \dots, v_n$ -- базис из вещественных векторов. 

Далее, если на $V$ была евклидова структура, то мы естественным образом продолжаем ее до унитарной структуры на комплексификации. 
Из евклидова пространства в комплексификации получается унитарное. 

Примерно на этом мы и остановились. Давайте теперь научимся продолжать операторы на комплексификациях.

\subsection*{Операторы на комплексификациях}

\begin{conj}
Пусть у нас был оператор $\A \in \End{V}$.
Тогда $\A_{\C} \in \End{V_{\C}}$ -- это оператор комплексификации. Задается он следующим образом:
\begin{gather*}
    \A_{\C}(v + iw) = Av + iAw
\end{gather*}
Проверка, что мы правда получили оператор, тривиальна. 
\end{conj}

\begin{conj}
Пусть $E$ -- базис $V$
Тогда в таком базисе матрица оператора комплексификации будет такой же, как и матрица самого оператора. 
\begin{gather*}
    [\A_{\C}]_{E} = [\A]_{E}
\end{gather*}
Так как у нас базисные вектора вещественные, то есть оператор комплексификации 
для них будет давать то же самое, что и просто оператор $\A$. 

Отсюда следует равенство характеристических многочленов, так как для его вычисления мы можем брать любой базис: 
\begin{gather*}
    \chi_{\A_{\C}} = \chi_{\A}
\end{gather*}
\end{conj}

\begin{lemma}
    \begin{gather*}
        (\A_{\C})^* = (\A^*)_{\C}
    \end{gather*}
\end{lemma}
\begin{proof}
    \emptyln
    Достаточно проверить, что выполняется характеристическое свойство:
    \begin{gather*}
        (\A(v + iw), v' + iw') \stackrel{?}{=} (v + iw, (\A^*)_{\C}(v' + iw'))
    \end{gather*}
    Давайте проверять:
    \begin{align*}
        (\A(v + iw), v' + iw') &= (A v, v') + (A w, w') + i ((A w, v') - (A v, w')) \\ 
        (v + iw, (\A^*)_{\C}(v' + iw')) &= (v, A^* v') + (w, A^* w') + i ( (w, A^* v') - (v, A^* w'))
    \end{align*}
    По характеристическому свойству для $\A$ эти штуки равны. 
\end{proof}

\follow $\A$ -- нормальный оператор $\Longrightarrow A_{\C}$ нормальный опреатор (используется факт, что комплексификация композиции -- это композиция их комплексификаций)

Пусть $\A$ -- нормальный оператор в евклидовом пространстве $V$. 
Рассмотрим его характеристический многочлен $\chi_{\A} \in \R[x]$. 
Если разложить его на линейные множители над полем комплексных чисел, то 
мнимые корни будут встречаться парами: 
\begin{gather*}
    \chi_{\A}(z) = 0 \Longrightarrow \chi_{\A}(\bar{z}) = 0
\end{gather*}
И кратность этих корней будет одинаковой, поэтому его можно записать в следующем виде: 
\begin{gather*}
    \chi_{\A} = \pm \prod_{p = 1}^{s} (x - \mu_p)^{a_p} \prod_{q = 1}^{t} (x - \lambda_q)^{b_q} (x - \overline{\lambda_q})^{b_q}, \text { где } \mu_p \in \R, \lambda_q \not \in \R
\end{gather*}

Отсюда мы получаем, что не вещественные собственные числа встречаются парами. Также у комплексносопряженных собственных значений будет одна и та же алгебраическая кратность. 
А так как опреатор диагонализируем, то совпадать будут и геометрические кратности. Если покопаться, то, на самом деле, можно сказать еще больше:

\begin{lemma}
    Пусть вектора $v_1 + iw_1, \dots, v_l + iw_l$ -- это базис $V_{\lambda}$, где $\lambda$ не вещественное, а $(V_{\lambda} = \Ker{\A_{\C} - \lambda \mathcal{E}})$.
    Тогда сопряженные к ним векторы $v_1 - iw_1, \dots, v_l - iw_l$~--- базис $V_{\bar{\lambda}}$

    Более того, если первый базис ортонормированный, то и второй ортонормированный.
\end{lemma}


\begin{proof} \quad 
    
Нетрудно проверить, что:
\begin{gather*}
    v + iw \in V_{\lambda} \Longrightarrow v - iw \in V_{\bar{\lambda}}
\end{gather*}
Также:
\begin{gather*}
    V_{\lambda} = \Lin(v_1 + iw_1, \dots, v_l + iw_l) \Longrightarrow V_{\bar{\lambda}} = \Lin(v_1 - iw_1, \dots, v_l - iw_l)
\end{gather*}
Давайте это проверим. Запишем произвольный вектор как линейную комбинацию базисных векторов: 
\begin{gather*}
    v + iw = \sum_{j = 1}^{l} (\alpha_j + i \beta_j) (v_j + i w_j) \Longrightarrow v - iw = \sum_{}^{} (\alpha_j - i \beta_j) (v_j - i w_j)
\end{gather*}
Аналогично преверяем линейную независимость и первое утверждение доказано. 

Теперь докажем утверждение про ортонормированность:
\begin{gather*}
    (v_j + i w_j, v_k + iw_k) = \delta_{jk} \Longrightarrow  (v_j - i w_j, v_k - iw_k) = \delta_{jk}
\end{gather*}
Просто применили комплексное сопряжение.
\end{proof}

\begin{theorem}
    Пусть $\A$ -- нормальный оператор в конечномерном евклидовом пространстве $V$.
    Тогда в некотором ортонормированном базисе матрица $\A$ блочно-диагональная и состоит из блоков 1 на 1 и блоков вида:
    \begin{gather*}
        \left(\begin{array}{cc}
            \alpha & \beta \\ 
            -\beta & \alpha
        \end{array}\right)
    \end{gather*}
\begin{proof}
    $\A$ -- нормальный оператор. Тогда:
    \begin{gather*}
        V_{\C} = \underbracket{V_{\mu_1}} \oplus \dots \oplus \underbracket{V_{\mu_s}} \oplus \underbracket{V_{\lambda_1} \oplus V_{\overline{\lambda_1}}} \oplus \dots \oplus \underbracket{V_{\lambda_t} \oplus V_{\overline{\lambda_t}}}
    \end{gather*}
    В каждом из вещественных слагаемых $V_{\mu_i}$ и в каждой паре слагаемых $V_{\lambda_i}$, $V_{\overline{\lambda_i}}$ выберем новый базис. 
    Тогда совокупность базисов составит ортонормированный вещественный базис всей комплексификации.
    
    Сначала разберемся с вещественными слагаемыми.
    Заметим, что в каждом таком кусочке можно выбрать вещественный базис.
    Этим и займемся. 
    Сперва выберем в $V_{\mu_p}$ произвольный базис. Он имеет следующий вид:
    \begin{gather*}
        v_1 + iw_1, \dots, v_l + i w_l
    \end{gather*}
    Из этого следует, что $V_{\mu_p} = \Lin (v_1, w_1, \dots, v_l, w_l)$. А тогда
    из этого набора можно выбрать вещественный базис для $V_{\mu_p}: u_1, \dots, u_l$. 
    Теперь мы этот базис ортогонализуем и нормируем. То есть получаем, что:
    \begin{gather*}
        \widetilde{u_1}, \dots, \widetilde{u_p} \text{ -- ортонормированный, вещественный базис } V_{\mu_p}
    \end{gather*}
    Тогда матрица оператора, индуцированного на соответствующем подпространстве будет выглядеть следующим образом: 
    \begin{gather*}
        [\A \, |_{V_{\mu_p} }]_{\dots} = \operatorname{diag} (\underbrace{\mu_p, \dots, \mu_p}_{\text{$l$ раз}})
    \end{gather*}
    Вместо базиса стоит троеточие потому что мы можем взять эту матрицу как в том базисе, который мы сейчас построили, так 
    и в любом другом, нам не принципиально. 

    Теперь разберемся с парными слагаемыми. Оператор 
    $\A |_{V_{\lambda_q} \oplus V_{\overline{\lambda_{q}}}}$. 
    \begin{gather*}
        v_1 + iw_1, \dots, v_l + iw_l \text{ -- ортонормированный базис } V_{\lambda_q}
    \end{gather*}
    По одной из предыдущих лемм мы знаем, что:
    \begin{gather*}
        v_1 - iw_1, \dots, v_l - iw_l \text{ -- ортонормированный базис } V_{\overline{\lambda_q}}
    \end{gather*}
    Выберем новый базис в сумме этих подпространств, взяв все $v$-шки и все $w$-шки. Прежде всего заметим, что:
    \begin{gather*}
        \Lin (v_1, w_1, \dots, v_l, w_l) = V_{\lambda_q} \oplus V_{\bar{\lambda_q}}
    \end{gather*}
    В то же время размерность $V_{\lambda_q} \oplus V_{\overline{\lambda_{q}}}$ равняется $2l$, то есть это базис. 
    Сейчас проверим, что он ортогонален.

    Для краткости обозначим за $u_j := v_j + iw_j$. Мы знаем, что:
    \begin{itemize}
        \item $(u_j, u_j) = 1$
        \item $(u_j, u_r) = 0, \quad j \neq r$
        \item $(u_j, \overline{u_j}) = 0$
        \item $(u_j, \overline{u_r}) = 0, \quad j \neq r$
    \end{itemize}
    Последние два равенства верны, потому что это собственные векторы, пренадлежащие разным собственным значениям, 
    а у нормального оператора они должны быть ортогональны друг другу.

    Если теперь уйти от введённого обозначения $u_j$ и расписать по линейности, то получим:
    \begin{enumerate}
        \item $ (v_j, v_j) + (w_j, w_j) = 1  $
        \item $ (u_j, \bar{u_j}) = 0 = (v_j + iw_j, v_j - iw_j) = (v_j, v_j) - (w_j, w_j) + i ( (w_j, v_j) + (v_j, w_j) )$
        \item $(u_j, u_r) = 0 = (v_j, v_r) + (w_j, w_r) + i ( (w_j, v_r ) - (v_j, w_r) )$
        \item $(u_j, \bar{u_r}) = 0 = (v_j, v_r) - (w_j, w_r) + i ( (w_j, v_r ) + (v_j, w_r) )$
    \end{enumerate}
    
    Раз последние два выражения равны нулю, то что вещественные, что мнимые части равны нулю. А тогда:
    \begin{gather*}
        (v_j, v_r) = (w_j, w_r) = (w_j, v_r) = (v_j, w_r) = 0
    \end{gather*}
    Из второго равенства следует, что $(v_j, w_j) = 0$.
    Из первого же мы понимаем, что $(v_j, v_j) = (w_j, w_j) = \frac{1}{2}$.

    Таким образом мы получили ортогональный базис в наборе из $2l$ векторов, где каждый вектор ортогонален каждому, кроме себя. Заметим, что но не нормирован, длина будет равна $\frac{1}{\sqrt{2}}$. В то же время это легко поправить, возьмем:
    \begin{gather*}
        \widetilde{v_j} = \sqrt{2} \cdot v_j, \widetilde{w_j} = \sqrt{2} \cdot w_j
    \end{gather*}
    Тогда $\widetilde{v_1}, \widetilde{w_1}, \dots, \widetilde{v_l}, \widetilde{w_l}$ -- ортонормированный базис $V_{\lambda_q} \oplus V_{\overline{\lambda_{q}}}$.

    Теперь хочется лишь понять, как будет выглядеть матрица нашего оператора в этом базисе. 
    Пусть $\lambda_q = \alpha_q + i \beta_q$. 
    Посмотрим на $\A_{\C}(v_j + iw_j)$:
    \begin{gather*}
        \A_{\C}(v_j + iw_j) = (\alpha_q + i \beta_q) (v_j + iw_j)
    \end{gather*}
    Тогда:
    \begin{align*}
        Av_j &= \alpha_q v_j -  \beta_q w_j \\
        Aw_j &= \beta_q v_j + \alpha_q w_j
    \end{align*}
    Аналогично для $A\widetilde{v_{j}}, A\widetilde{w_{j}}$

    Тем самым: 

    Пусть $U_q = \Lin (\underbrace{\widetilde{v_1}, \widetilde{w_1}, \dots, \widetilde{v_l}, \widetilde{w_l}}_{\text{$ E_q $}} )$, тогда:
    
    \begin{gather*}
        [\A |_{U_q}]_{E_q} = \left(\begin{array}{cccccc}
        \alpha_q & \beta_q  & 0       & \dots    & 0        & 0\\ 
        -\beta_q & \alpha_q & 0       & \dots    & 0        & 0\\ 
        0        & 0        & \ddots  &          & \vdots   & \vdots \\ 
        \vdots   & \vdots   &         & \ddots   & 0        & 0 \\
        0        & 0        &  \dots  & 0        & \alpha_q & \beta_q \\ 
        0        & 0        & \dots   & 0        & -\beta_q & \alpha_q
        \end{array}\right)
    \end{gather*}   
\end{proof} 
\end{theorem}

\textbf{Частные случаи}:
\begin{enumerate}
    \item $\A$ -- самоспопряжённый тогда и только тогда, когда матрица $\A$ в некотором ортонормированном базисе диагональна. 
    \begin{gather*}
        \A = \A^* \Longrightarrow [\A]_{E} = [\A]^T_{E} \\
        \left(\begin{array}{cc}
        \alpha & \beta \\ 
        -\beta & \alpha
        \end{array}\right) = \left(\begin{array}{cc}
        \alpha & -\beta \\ 
        \beta & \alpha
        \end{array}\right) 
        \Longrightarrow \beta = 0 \Longrightarrow [\A]_{E} \text{ диагональна}
    \end{gather*}
    В обратную сторону тривиально. 
    \item $\A$ -- ортогональный:
    \begin{align*}
        \A \A^* = \mathcal{E} &\Longleftrightarrow [\A]_{E} \cdot [\A]^T_{E} = E_n \\
                              &\Longleftrightarrow \text{ для всех блоков } B \text{ выполняется, что } BB^T = E_{\dots}
    \end{align*}
    Таким образом, если блок $B$ был блоком $1 \times 1$ вида $(\mu)$, то $\mu^2 = 1 \Longrightarrow \mu = \pm 1$. Если же блок имел размер $2 \times 2$, то:
    \begin{gather*}
        B = \left(\begin{array}{cc}
            \alpha & \beta \\ 
            -\beta & \alpha
            \end{array}\right) \Longrightarrow BB^T = \left(\begin{array}{cc}
            \alpha^2 + \beta^2 & 0 \\ 
            0 & \alpha^2 + \beta^2
        \end{array}\right) = E_2
        \Longleftrightarrow \alpha^2 + \beta^2 = 1
    \end{gather*}

    Еще подметим, что, в общем то, можно ввести такое $\varphi$, что:
    \begin{gather*}
        \begin{cases}
            \alpha = \cos{\varphi} \\
            \beta = \sin{\varphi}
        \end{cases} 
    \end{gather*}

    Тогда $\A$ ортогональный оператор $\Longleftrightarrow$ матрица $\A$ в 
    некотором ортонормированном базисе имеет блочно-диагональный вид с блоками $1 \times 1$ вида $(\pm 1)$ и
    блоками $2 \times 2$ вида:
    \begin{gather*}
        \left(\begin{array}{cc}
            \cos{\varphi} & \sin{\varphi} \\ 
            -\sin{\varphi} & \cos{\varphi}
        \end{array}\right)
    \end{gather*}

    Логика повествования давно пошла по жопе. Давайте в очередной раз заметим, что можно еще упростить вид нашей матрицы. 

    Воспользуемся тем, что блоки мы можем переставлять как душе угодно. Давайте в начало сгребем все блоки $2 \times 2$, потом единичные блоки 
    с единицей, а в самый конец единичные блоки с минус единицей. После этого 
    заметим, что два подряд идущих блока единиц можно преобразовать в блок $2 \times 2$. Аналогично с блоками из $-1$: 
    \begin{gather*}
        \left(\begin{array}{cc}
            1 & 0 \\ 
            0 & 1
        \end{array}\right) = \left(\begin{array}{cc}
            \cos{0} & \sin{0} \\ 
            -\sin{0} & \cos{0}
        \end{array}\right) \qquad \qquad
        \left(\begin{array}{cc}
            -1 & 0 \\
            0 & -1
        \end{array}\right) = \left(\begin{array}{cc}
            \cos{\pi} & \sin{\pi} \\
            -\sin{\pi} & \cos{\pi}
        \end{array}\right)
    \end{gather*}
    Теперь обозначим блоки $2 \times 2$ буковками $R$ от слова rotation и посмотрим на финальный вид нашей матрицы: 
    \begin{gather*}
        [\A]_{E} = \left(\begin{array}{cccc}
            R_{\varphi_1} &  &  & 0 \\ 
            & \ddots &  &  \\ 
            &  & R_{\varphi_m} &  \\ 
            0 &  &  & D
        \end{array}\right)
    \end{gather*}
    Где $D$ будет либо пустым, либо равен $(\pm 1)$, либо же блоку:
    \begin{gather*}
        \left(\begin{array}{cc}
            1 & 0 \\ 
            0 & -1
        \end{array}\right)
    \end{gather*}
    В частности, если $\dim V = 3$, то любой оператор первого рода, то есть такой, что его определитель равен $1$, а еще точнее просто ортогональный 
    (так как ортогональность влечет то, что у оператора опеределитель равен $\pm 1$), 
    в некотором базисе $E$ будет иметь следующую матрицу:
    \begin{gather*}
        [\A]_{E} = \left(\begin{array}{cc}
            R_{\varphi} & 0 \\ 
            0 & 1 
        \end{array}\right)
    \end{gather*}
    То есть наш оператор будет представлять из себя просто поворот на угол $\varphi$ в некоторой плоскости. 
    На самом деле получили красивый геометрический факт. Пусть мы взяли композицию двух поворотов на некоторые 
    углы относительно двух разных осей, проходящих через начало координат. И оказывается, мы сейчас поняли, 
    что композиция этих поворотов тоже будет поворотом на некий угол, по некоторой оси, проходящей через начало координат. 
\end{enumerate}

\begin{theorem}(Характеристика ортогональных операторов)

    Пусть $V$ -- евклидово пространство, $\A \in \End{V}$.
    Тогда эквивалентны следующие утверждения:
    \begin{enumerate}
        \item $\A$ ортогонален
        \item $\forall v, w \in V: (\A v, \A w) = (v, w)$
        \item $\forall v \in V: ||\A v|| = || v || $
    \end{enumerate}
    \mybox[orange!15]{Грубо говоря ортогональный оператор -- оператор, сохраняющий длины векторов и сохраняющий начало координат. В общем то 
    из этого предложения становится интуитивно понятно, почему у ортогональого оператора опеределитель $\pm 1$. 
    Ведь в терминах операторов определитель -- это то, как сильно оператор изменяет длины векторов.}
    \begin{proof} \quad

        \begin{itemize}
            \item[``$1 \Rightarrow 2$'':]
            \begin{gather*}
                \A^* \A = \mathcal{E} \\
                (\A v, \A w) = (v, \A^*\A w) = (v, w)
            \end{gather*} 
            \item[``$2 \Rightarrow 3$'':]
            \begin{gather*}
                ||Av|| = \sqrt{(Av, Av)} = \sqrt{(v, v)} = ||v||
            \end{gather*} 
            \item[``$3 \Rightarrow 2$'':]
            \begin{align*}
                2(v, w) &= ||v + w||^2 - ||v||^2 - ||w||^2 \\
                2(Av, Aw) &= ||Av + Aw||^2 - ||Av||^2 - ||Aw||^2 \\
                &\Longrightarrow (Av, Aw) = (v, w)
            \end{align*}  
            \item[``$2 \Rightarrow 1$'':]  \quad
             
            Нужно доказать, что $\forall v \in V: \, \A^* \A v = v$. Возьмем произвольный $w \in V$:
            \begin{align*}
                (w, \A^* \A v) &= (\A w, \A v) = (w, v) \\
                &\Longrightarrow (\A^* \A v - v) \perp w \\
                &\Longrightarrow (\A^* \A v - v) \in V^{\perp} = 0 \\
                &\Longrightarrow \A^* \A v = v
            \end{align*} 
        \end{itemize}
    \end{proof}    
\end{theorem}


\subsection{Операторы проектирования}
Понятие оператора проектирования можно ввести в любом пространстве. Пусть у нас есть 
векторное пространство, которое раскладывается в прямую сумму подпространств: $V = W_1 \oplus W_2$. 

\begin{conj}
    Если для оператора $\A \in \End{V}$ выполняется, что:  
    $\A(w_1 + w_2) = w_1$, то $\A$ называется \textbf{оператором проектирования} на $W_1$ вдоль $W_2$. 
\end{conj}

\begin{theorem}
    Пусть $\A \in \End{V}$. 
    Тогда эквивалентны следующие условия:
    \begin{enumerate}
        \item $\A$~--- оператор проектирования (т.е. $\exists W_1, W_2$, т.ч. $V = W_1 \oplus W_2$ и 
            $\A$ -- оператор проектирования на $W_1$ вдоль $W_2$)
        \item $\A^2 = \A$ (идемпотентность)
    \end{enumerate}
    \begin{proof} \quad

        \begin{itemize}
            \item[``$1 \Rightarrow 2$'':]
            \begin{align*}
                \A^2 (w_1 + w_2) &= \A(w_1) \\
                &= \A(w_1 + 0) \\
                &= w_1 \\
                &= \A(w_1 + w_2)
            \end{align*}
            \item[``$2 \Rightarrow 1$'':] Ручками введем необходимые нам подпространства. 
                Пусть $W_1 = \Imm{\A}$, а $W_2 = \Ker{\A}$. 
                Хотим проверить, что $V = W_1 \oplus W_2$:
                \begin{gather*}
                    v = \inbelow{\A v }{W_1} + \inbelow{\underbrace{(v - \A v)}}{W_2}
                \end{gather*}
                Так как $\A(v - \A v) = \A v - \A^2 v = 0$. \\
                При этом, когда у нас что-то попадает в пересечение, то есть когда $w \in W_1 \cap W_2$, 
                то $Aw = A^2 w = Av = w$. С другой стороны при этом $w \in W_2$, то есть мы попали в ядро, а значит $Aw = 0$.
                
                Мы доказали, что получилось прямая сумма, осталось доказать, что выполянется нужное свойство. Проверим его: 
                \begin{gather*}
                    A(\inbelow{w_1}{W_1}  + \inbelow{w_2}{W_2} ) = \stackbelow{A w_1}{w_1}  + \stackbelow{A w_2}{0}
                \end{gather*}
                То что нужно. То есть $\A$ -- оператор проектирования на $W_1$ вдоль $W_2$. 
        \end{itemize}
    \end{proof}
\end{theorem}

\begin{conj}
    Пусть $V$ --- евклидово или унитарное, $W \subset V$ -- его подпространство. 
    Оператор проектирования на $W$ вдоль $W^{\perp}$ называется \textbf{оператором ортогонального проектирования} на $W$.
\end{conj}

\begin{theorem} (Характеристика оператора ортогонального проектирования)

    Пусть $\A \in \End{V}$. 
    Тогда эквивалентны следующие условия:
    \begin{enumerate}
        \item $\A$ оператор ортогонального проектирования
        \item $\A$ самоспопряжённый идемпотентный
    \end{enumerate}

    \begin{proof} \quad 
    
    \begin{itemize}
        \item[``$1 \Rightarrow 2$'':]
            То, что он идемпотентный знаем, осталось проверить самоспопряжённость. 
            Пусть $e_1, \dots, e_m$ --- ортонормированный базис $W$, а $e_{m + 1}, \dots, e_n$ ортонормированный базис $W^{\perp}$.
            Также пусть $E := (e_1, \dots, e_n)$. Тогда:
            \begin{gather*}
                [\A]_E = \left(\begin{array}{cc}
                E_m & 0 \\ 
                0 & 0
                \end{array}\right)
            \end{gather*}
            Ну а тогда:    
            \begin{gather*}
                [\A]^*_E = \left(\begin{array}{cc}
                E_m & 0 \\ 
                0 & 0
                \end{array}\right) = [\A]_E \Longrightarrow \A^* = \A
            \end{gather*}
            Что и означает самоспопряжённость.
        \item[``$2 \Rightarrow 1$'':]  
            В следующий раз
    \end{itemize}
    \end{proof}
\end{theorem}
