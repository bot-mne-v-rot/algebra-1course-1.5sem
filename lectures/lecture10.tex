\section{Лекция номер 10}
\begin{conj}
    Пусть у нас есть $\B$ -- билинейная форма на $V$. И есть два вектора $u, v \in V$. Говорят, что векторы 
    $u$ и $v$ ортогональны, если $\B(u, v) = 0$.
\end{conj}

Если $\B$ симметричная билинейная форма, то это симметричное отношение.
Ортогональность векторов $u$ и $v$ обозначают как $u \perp v$.

\begin{conj}
    Базис $e_1, \dots, e_n$ пространства $V$ будем называть ортогональным, если $e_i \perp e_j \forall i \neq j$. 
\end{conj}

\begin{theorem}
    (Лагранжа) Пусть $\B$ -- симметрическая билинейная форма на $V$, $\dim V = n < + \infty$. Тогда в $V$ существует ортогональный
    базис.
\end{theorem}
\begin{proof}
    Докажем теорему индукцией по размерности $V$. 
    \begin{itemize}
        \item База $n = 1$. Тогда любой базис ортогонален. 
        \item Переход $n-1 \to n$. Начнем с того, что может быть случай, когда форма нулевая. Тогда любой базис ортогональный. 
        
        В случае, если форма ненулевая, то должен существовать вектор $e_1 \in V : \B(e_1, e_1) \neq 0$. Предположим, что это не так. 
        То есть $\forall v \in V : \B(v, v) = 0$. Введем обозначение $q(v) := \B(v, v)$. Теперь самое время нам вспомнить про замечательную формулу: 
        \begin{gather*}
            \forall u, v \in V : \B(u, v) = \frac{1}{2} (q(u+v) - q(u) - q(v))
        \end{gather*}
        Из такого равенства очевидно, что если $q$ -- нулевая квадратичная форма, то $\B$ -- нулевая билинейная форма. Получаем противоречие.

        Теперь давайте рассмотрим множество всех векторов, ортогональных к $e_1$: $W = \{ w \in V \mid e_1 \perp w \}$ -- линейное подпространство в $V$. 
        Рассмотрим следующее отображение: 
        \begin{gather*}
            \lambda: V \longrightarrow K \\
            v \longmapsto \B(v, e_1)
        \end{gather*}
        Заметим, что образ $\lambda$ не может быть равен 0, так как $\B(e_1, e_1) \neq 0$. А значит $\Imm{\lambda} = K$, так как $K$ -- одномерное линейное пространство, то есть 
        подпространство может быть либо нулевым, либо всем пространством. 

        Таким образом:
        \begin{align*}
            \dim{W} &= \dim{\Ker{\lambda}} \\
            &= \dim{V} - \dim{\Imm{\lambda}} \\
            &= n - 1
        \end{align*}
        Заметим, что $\B$ можно ограничить на декартов квадрат $W$. То есть $\B' = \B \mid_{W \times W}$ -- симметрическая билинейная форма на $W$. Размерность пространства мы получили 
        на 1 меньше, так что, по индукционному предположению у 
        $W$ существует ортогональный базис $e_2, \dots, e_n$. Заметим теперь, что у нас есть пространство размерности $n-1$ и есть вектор $e_1$, который не принадлежит $\Lin{(e_2, \dots, e_n)}$. Тогда все 
        вектора $e_1, \dots, e_n$ -- ЛНС. А значит это наш искомый ортогональный базис $V$. 
    \end{itemize}
\end{proof}    
\notice $E$ -- ортогональный базис $V$ по отношению к форме $\B \Longleftrightarrow$ матрица $\B$ в этом базисе диагональная.

Мы пока что не до конца решили классификаицонную задачу, так как мы пока что не знаем, могут ли разные диагональные матрицы оказаться матрицами Грама одной и той же 
билинейной формы в разных базисах?

\notice $E = (e_1, \dots, e_n)$ -- ортогональный базис $V$, $E' = (\alpha_1 e_1, \dots, \alpha_n e_n)$. Пускай 
$[\B]_E = \diag{\lambda_1, \dots, \lambda_n}$. Тогда в базисе $E'$ форма $\B$ тоже будет иметь диагональную матрицу. 
Проверим, что будет стоять на диагонали: 
\begin{gather*}
    \B(\alpha_i e_i, \alpha_i e_i) = \alpha_i^2 \B(e_i, e_i) = \alpha_i^2 \lambda_i
\end{gather*}
То есть $[\B]_{E'} = \diag{\alpha_1^2 \lambda_1, \dots, \alpha_n^2 \lambda_n}$. Отсюда уже видно, что $\lambda_1, \dots, \lambda_n$ -- не инвариант матрицы, так что ответ на вопрос, которым
мы задавались выше -- нет. 

\begin{theorem-non}
    Пусть $V$ -- конечномерное линейное пространство над $\C$, $\B$ -- симметрическая билинейная форма. Тогда существует 
    базис $E$ пространства $V$, такой, что: 
    \begin{gather*}
        [\B]_E = \begin{pmatrix*}
            E_r & 0 \\
            0 & 0
        \end{pmatrix*} 
    \end{gather*} 
    Для некоторого $r$ -- инварианта $\B$. То есть такое условие может выполняться для нескольких различных базисов, но $r$ всегда будет получться одно и то же. 
\end{theorem-non}
\begin{proof}
    Так как диагонализировать мы уже умеем, существует $E_0 = (e_1, \dots, e_n)$, такой, что: 
    \begin{gather*}
        [\B]_{E_0} = \diag{\lambda_1, \dots, \lambda_n}
    \end{gather*}
    Мы можем перенумеровать лямбды так, что $\lambda_1, \dots, \lambda_r \neq 0$, а $\lambda_{r+1} = \dots = \lambda_n = 0$. 

    Для любого $j$ существует $\alpha_j \in \C : \alpha_j^2 = \lambda_j$. 
    Построим $E = (\alpha^{-1}_1 e_1, \dots, \alpha^{-1}_r e_r, e_{r+1}, \dots, e_n)$. 
    Тогда: 
    \begin{gather*}
        [\B]_E = \diag{\underbrace{\alpha_1^{-2} \lambda_1, \dots, \alpha_r^{-2} \lambda_r}_{1, \dots, 1}, \underbrace{\lambda_{r+1}, \dots, \lambda_n}_{0, \dots, 0}}
    \end{gather*}
    То есть мы получили матрицу, нужного нам вида. Осталось понять, что $r$ -- инвариант. Для этого хватает вспомнить, что: 
    \begin{gather*}
        r = \rk{\begin{pmatrix*}
            E_r & 0 \\
            0 & 0
        \end{pmatrix*}} = \rk{\B}
    \end{gather*}
    Так что $r$ -- очевидным образом инвариант. 
\end{proof}
\begin{theorem} (Закон инерции вещественных билинейных форм)

    Пусть $V$ -- конечномерное линейное пространство над $\R$, $\B$ -- симметрическая билинейная форма на $V$. Тогда 
    существует такой базис $E$, такой, что: 
    \begin{gather*}
        [\B]_E = \diag{\underbrace{1, \dots, 1}_s, \underbrace{-1, \dots, -1}_t, 0, \dots, 0}
    \end{gather*}
    При этом $s$ и $t$ -- инварианты $\B$ 
\end{theorem}
\begin{proof} \quad

    Существование $E$ доказывается аналогично предыдущему предложению. 
    Только нужно будет взять квадратный корень из модуля чисел на диагонали. Каждое число поделится на свой модуль и останутся 1 и -1.
    То, что $s+t$ -- инвариант, тоже понятно, так как $s+t = \rk{[\B]_E} = \rk{\B}$. 

    То есть единственное, что нам нужно доказать -- это что $s$ -- инвариант. Предположим обратное.     
    Тогда существуют $E_1$ и $E_2$:
    \begin{gather*}
        [\B]_{E_1} = \diag{\underbrace{1, \dots, 1}_{s_1}, \underbrace{-1, \dots, -1}_{t_1}, 0, \dots, 0} \qquad 
        [\B]_{E_2} = \diag{\underbrace{1, \dots, 1}_{s_2}, \underbrace{-1, \dots, -1}_{t_2}, 0, \dots, 0}
    \end{gather*}
    Причем $s_1 \neq s_2$. НУО скажем, что $s_1 > s_2$. Пусть $E_1 = (e_1, \dots, e_n), E_2 = (f_1, \dots, f_n)$. Введем
    $U_1 := \Lin{(e_1, \dots, e_{s_1})}, U_2 := \Lin{(f_{s_2 + 1}, \dots, f_n)}$. Обратим внимание, что: 
    \begin{gather*}
        \forall v \in U_1, v \neq 0: \B(v, v) > 0
    \end{gather*}
    Давайте убедимся, что это правда: 
    \begin{gather*}
        v = \alpha_1 e_1 + \dots + \alpha_{s_1} e_{s_1} (\text{и } \exists \nu : \alpha_\nu \neq 0 \text{ т. к. } v \neq 0) \Longrightarrow \\
        \B(v, v) = \sum\limits_{i=1}^{s_1} \alpha_i^2 > 0
    \end{gather*}
    Аналогичными рассужденяими придем к выводу, что $\forall v \in U_2 : \B(v, v) \leqslant 0$: 
    \begin{gather*}
        v = \alpha_{s_2 + 1} f_{s_2 + 1} + \dots + \alpha_n f_n \\
        \B(v, v) = \sum\limits_{i = s_2 + 1}^n \alpha_i^2 \B(f_i, f_i) = - \sum\limits_{s_2 + 1}^{s_2 + t_2} \alpha_i^2 \leqslant 0
    \end{gather*}
    Что же мы получили? Мы получили, что $U_1 \cap U_2 = 0$. На самом деле, мы можем уже сказать, что получили противоречие, но, давайте поймем почему: 
    \begin{gather*}
        \dim{U_1} = s_1 \qquad \dim{U_2} = n - s_2 \\
        \dim{U_1} + \dim{U_2} = s_1 + n - s_2 > n \\ 
        (\text{т. к. мы фиксировали, что } s_1 > s_2)
    \end{gather*}
    Теперь видно, где собака зарыта. У нас есть формула для пересечения подпространств, подставив в которую $U_1$ и $U_2$ получим: 
    \begin{gather*}
        \dim{U_1 \cap U_2} = \overbrace{\dim{U_1} + \dim{U_2}}^{> n} - \underbrace{\dim{(U_1 + U_2)}}_{\leqslant n} > 0
    \end{gather*}
    Противоречие.
\end{proof}
\begin{conj}
    $(s, t)$ -- сигнатура $\B$. Иногда можно услышать характеристику наподобие ``Форма ранга $r$ и сигнатуры $t$''. 
    Это будет значить, что ее сигнатура -- это $(r-t, t)$.
\end{conj}
\subsection{Евклидовы пространства}
\begin{conj}
    Симметрическая билинейная форма $\B$ на $V_\R$ называется положительно определенной, если 
    $\forall v \in V : \B(v ,v) \geqslant 0$ и $\B(v, v) > 0$ при $v \neq 0$.
\end{conj}
Аналогично определяются понятия отрицательной, неположительной и неотрицательной билинейных форм. 

Если речь идет о конечномерных пространствах, там у нас есть сигнатура $(s, t)$ и размерность пространства $n$. И получается, что: 
\begin{itemize}
    \item Положительная определенность равносильна тому, что $s = n$ 
    \item Неотрицательная определенность $\Longleftrightarrow t = 0$
    \item Отрицательная определенность $\Longleftrightarrow t = n$
    \item Неотрицательная определенность $\Longleftrightarrow s = 0$
\end{itemize} 

\begin{conj}
    Евклидово пространство -- линейное пространство над $\R$ с фиксированной положительно определенной симметрической 
    билинейной формой. Обычно значение этой билинейной формы на векторах $u$ и $v$ обозначают как $(u, v)$, а саму форму называют скалярным произведением. 
\end{conj}

\underline{Примеры:} 
\begin{enumerate}
    \item $V = \R^n$. Задано стандартное скалярное произведение: 
    \begin{gather*}
        \left(\left(\begin{array}{c}
            \alpha_1 \\ 
            \vdots \\ 
            \alpha_n
            \end{array}\right), 
            \left(\begin{array}{c}
            \beta_1 \\ 
            \vdots \\ 
            \beta_n
            \end{array}\right)\right) 
            = \alpha_1 \beta_1 + \dots + \alpha_n \beta_n
    \end{gather*}
    \item $V = C[0, 1]$
    \begin{gather*}
        (f, g) = \int\limits_{0}^{1} fg
    \end{gather*}
\end{enumerate}
Дальше будем считать, что $V$ -- евклидово пространство.
\begin{conj}
    Пусть $v \in V$. Длина(норма) $v$ обозначется как $\abs{v} = \sqrt{(v, v)}$.
\end{conj} 

\begin{theorem-non}
    (Неравенство КБШ) 

    Пусть $v, w \in V$. Тогда: 
    \begin{gather*}
        \abs{(v, w)} \leqslant  \abs{v} \cdot \abs{w}
    \end{gather*}
\end{theorem-non}
\begin{proof}
    Возьмем произвольное $t \in \R$ 
    \begin{gather*}
        (v + tw, v + tw) \geqslant 0 \\
        (v, v) + t^2 (w, w) + t (v, w) + t (w, v) = \\
        \abs{w}^2 t^2 + 2 (v, w) t + \abs{v}^2
    \end{gather*}
    Значения этого трехчлена неотрицательны, когда $t$ пробегает вещественные числа, значит соответствующее 
    квадратное уравнение имеет не более одного корня, а значит дескриминант $D \leqslant 0$.
    Посчитаем дескриминант и получим нужное нам неравенство: 
    \begin{gather*}
        \frac{D}{4} = (v, w)^2 - \abs{w}^2 \cdot \abs{v}^2 \leqslant 0 \\
        \abs{(v, w)} \leqslant  \abs{v} \cdot \abs{w}
    \end{gather*} 
\end{proof}
\follow Пусть $v, w \in V$. Тогда $\abs{v + w} \leqslant \abs{v} + \abs{w}$.
\begin{proof}
    \begin{align*}
        \abs{v + w}^2 &= (v + w, v + w) \\
        &= (v, v) + (w, w) + 2(v, w) \\
        &\leqslant \abs{v}^2 + \abs{w}^2 + 2\abs{v} \cdot \abs{w} \\
        &= (\abs{v} + \abs{w})^2
    \end{align*}
\end{proof}

\notice В евклидовом пространстве можно ввести метрику: $\rho(v, w) = \abs{v - w}$. Аксиомы метрики очевидны из положительной определенности 
и из только что доказанного неравенства.

Также можно ввести понятие угла между векторами. Пусть $v, w \neq 0$. Тогда угол между $v$ и $w$ -- это $\alpha \in [0, \pi]$, такой, что $(v, w) = \abs{v} \cdot \abs{w} \cdot \cos{\alpha}$. 
\begin{gather*}
    -1 \leqslant \frac{(v, w)}{\abs{v} \cdot \abs{w}} \leqslant 1
    \Longrightarrow \exists ! \ \alpha \in [0, \pi] : \cos{\alpha} = \frac{(v, w)}{\abs{v} \cdot \abs{w}}
\end{gather*}
\begin{conj}
    Базис $E$ евклидова пространства $V$ называется ортонормированным, если матрица скалярного произведения в нем равна единичной матрице. То есть если $\forall i, j: (e_i, e_j) = \delta_{ij}$, где 
    $e_1, \dots, e_n$ -- базисные вектора $E$.  
\end{conj}
Давайте теперь опишем алгоритм построения ортонормированного базиса. 
\begin{theorem-non} (Ортогонализация Грама-Шмидта)

    Пусть $f_1, \dots, f_n$ -- произвольный базис $V$. Тогда в $V$ существует ортонормированный базис $e_1, \dots, e_n$, причем $\forall j : e_j \in \Lin{(f_1, \dots, f_j)}$.  
\end{theorem-non}
\begin{proof}
    Наш ортонормированный базис будем строить рекурсивно. Первый вектор $e_1 = \frac{1}{\abs{f_1}} f_1$. Теперь пусть $k$ векторов $e_1, \dots, e_k$, где $k < n$ уже построены. Построим очередной вектор.  
    \begin{gather*}
        e_{k+1}^\circ = f_{k+1} + \alpha_1 e_1 + \dots + \alpha_k e_k
    \end{gather*} 
    То, что $e_{k+1}^\circ \in \Lin{(f_1, \dots, f_{k+1})}$ -- очевидно. Нужно выбрать такие $\alpha$, чтобы была ортогональность. Значит хотим, чтобы выполнялось равенство:
    \begin{gather*}
        (e_{k+1}^\circ, e_j) = 0, \; j=1, \dots, k \\
        (e_{k+1}^\circ, e_j) = (f_{k+1}, e_j) + \alpha_j \Longrightarrow \alpha_j = -(f_{k+1} , e_j)
    \end{gather*} 
    Получаем, что: 
    \begin{gather*}
        e_{k+1}^\circ = f_{k+1} - \sum\limits_{j=1}^k (f_{k+1}, e_j)e_j
    \end{gather*}
    Ортогональность есть, пренадлежность линейной комбинации $f$ тоже есть, осталось нам этот вектор отнормировать. Получаем: 
    \begin{gather*}
        e_{k+1} = \frac{1}{\abs{e_{k+1}^\circ}} \cdot e_{k+1}^\circ
    \end{gather*}
    Ортогональность никуда не делась, а ортонормированность появилась. 
\end{proof}
Когда у нас уже есть некий ортонормированный базис, задать новый базис -- это то же самое, что задать матрциу перехода. Вопрос следующий: Какой должна быть 
матрица перехода, чтобы получающийся базис был ортонормированный? Ответ на этот вопрос мы собственно уже знаем.  
Новый базис будет ортонормированным, если матрица Грама формы $\B$ в новом базисе будет единичной. Мы знаем, что: 
\begin{gather*}
    [\B]_{E'} =C^T [\B]_E C
\end{gather*}
Раз исходный базис ортонормированный, то $[\B]_E$ -- единичная. Легко видеть, что $[\B]_{E'}$ будет единичной тогда и только тогда, когда $C^T C = E_n$ 
\begin{conj}
    Матрица $C$ называется ортогональной, если $C^T C = E_n$ 
\end{conj}
Итого, отвечая на наш вопрос, можно сказать, что новый базис будет тоже ортонормированным, если и только если матрциа перехода была ортогональной матрицей.