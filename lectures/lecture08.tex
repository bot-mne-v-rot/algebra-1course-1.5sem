\section{Лекция номер 8}

\begin{theorem}(О диогонализации оператора и характеристическом многочлене)

    Пусть $\A \in \End{V}$.

    Тогда эквивалентны 2 утверждения:
    \begin{enumerate}
        \item $\A$ диагонализируемый
        \item $\chi_{\A}$ раскладывается на линейные множители
        и для любого собственного значения $\lambda:$
        \[ g_{\lambda} = a_{\lambda} \]
    \end{enumerate}

    \begin{proof} \quad

    \quad$1 \Longrightarrow 2:$
    Знаем, что матрица оператора $\A$ в некотором базисе $E$ выглядит так: 
    \[
        \left(\begin{array}{ccc}
            \lambda_1 &  & 0 \\ 
            & \ddots &  \\ 
            0 &  & \lambda_n
        \end{array}\right)
    \]

    Очевидно, что характеристический многочлен этого оператора выглядит так:
        \[ \chi_{\A} = \prod_{i = 1}^{n} (\lambda_i - x) \]
    По определению $g_{\lambda}$ равно максимальному числу линейно независимых векторов, принадлежащих собственному значению $\lambda$.
    Базисные векторы у нас линейно независимы, поэтому $g_\lambda$ равно числу вхождений $\lambda$ в $\{ \lambda_1, \dots, \lambda_n \}$ (вообше это надо бы построже доказать, но в целом это очевидно).
    Алгебраическая кратность $\lambda$ это кратность $\lambda$ как корня $\chi_\A$, что по сути то же самое, поэтому $g_\lambda = a_\lambda$.
    
    \quad$2 \Longrightarrow 1:$
    Пусть $\lambda_1, \dots, \lambda_m$ -- все собственные значения без повторений.
    Тогда \[ a_{\lambda_1} + \dots + \alpha_{\lambda_m} = \deg{\chi_{\A}} = n \Longrightarrow g_{\lambda_1} + \dots + g_{\lambda_m} = n \Longrightarrow \A \text{ диагонализируем} \]
    \end{proof}
\end{theorem}

С помощью этого предложения мы теперь видим две причины, по которым оператор может быть не диагонализируем:
\begin{enumerate}
    \item Характеристический многочлен может не раскладываться на линейные множители (поле $K$ не является алгебраически замкнутым).
    \item Алгебраическая и геометрическая кратности какого-то собственного значения просто напросто отличаются.
\end{enumerate}

\vspace*{4mm}

\underline{Рассмотрим примеры:}
\begin{enumerate}
    \item Пусть $ K = \R$, $V$ -- произвольное двумерное, $E$ -- его базис, и матрица оператора имеет вид \[ [\A]_{E} = \left(\begin{array}{cc}
    0 & 1 \\ 
    -1 & 0
    \end{array}\right) \] 
    Тогда $\chi_{\A} = x^2 + 1$. 
    У этого многочлена нет корней в $R$, следовательно, $\A$ не диагонализируемый.

    \item Пусть $K = \C$, $V$ -- произвольное двумерное, $E$ -- его базис, и матрица оператора имеет вид
    \[ [\A]_{E} = \left(\begin{array}{cc}
        0 & 0 \\ 
        1 & 0
    \end{array}\right)\] 
    Тогда $\chi_\A = x^2$, а это означает, что $a_0 = 2$.
    Заметим, что наш оператор действует так: $e_1 \mapsto e_2 \mapsto 0$.
    Значит, только вектор $e_2$ и все кратные ему переходят в 0 $\Rightarrow g_0 = \Lin(e_2) = 1$.
    Получили, что $g_0 < a_0 \Longrightarrow \A$ не диагонализируемый.
\end{enumerate}

\vspace*{5mm}

Тем не менее, ситуация номер 2 ставится "под контроль".
Даже если оператор не диагонализируем, но его характеристический многочлен раскладывается на линейные множители, то матрицу оператора можно привести к достаточно простому виду, называемому жордановым.

\subsection{Жорданова форма}

\begin{conj}
    Жорданова клетка порядка $m$ с собственным значением $\lambda$: 
    \[ J_m(\lambda) = \left(\begin{array}{cccc}
    \lambda &  &  & 0 \\ 
    1 & \lambda &  &  \\ 
     & \ddots & \ddots &  \\ 
    0 &  & 1 & \lambda
    \end{array}\right) \in M(m, K) \]
    (на главной диагонали стоят $\lambda$, под ними единицы, остальные нули).
\end{conj}

\vspace*{3mm}

Посмотрим на характеристический многочлен.
Матрица является нижнетреугольной, поэтому ее определитель равен произведению элементов на главной диагонали:
    \[  \chi(x) = (\lambda - x)^m \]
Сразу видно, что: $a_{\lambda} = m$.

Посчитаем геометрическую кратность. 
Обозначим за $\A := J_m \cdot$ -- оператор умножения на эту матрицу (то есть это оператор, у которого в каком-то базисе $E$ ровно такая матрица).
Тогда $ g_{\lambda} = \dim \Ker(\A - \lambda\mathcal{E})$. 
Заметим, что $[\A - \lambda\mathcal{E}]_E = J_{m}(0)$.
Таким образом, матрица оператора $\A - \lambda\mathcal{E}$ имеет вид:
\[ \left(\begin{array}{cccc}
0 &  &  & 0 \\
1 & 0 &  &  \\
 & \ddots & \ddots & 0 \\ 
0 &  & 1 & 0
\end{array}\right) \]

А значит, оператор будет действовать так: $e_1 \mapsto e_2 \mapsto \dots \mapsto e_m \mapsto 0$.
То есть только векторы, кратные $e_m$, будут переходить в 0, а это означает, что $g_\lambda = 1$.

\vspace*{4mm}

\begin{conj}
    Жорданова матрица -- это блочно-диагональная матрица, у которой блоки -- жордановы клетки.
\end{conj}
У блоков могут быть одинаковые, а могут быть и разные собственные значения.

Ключевое утверждение, связанное с жордановой формой, заключается в том, что 
если характеристический многочлен оператора можно разложить на линейные множители,
то в некотором базисе его матрица становится жордановой.
Эта теорема будет доказана позднее.

\subsection{Аннулирующие многочлены}

Сейчас мы будем заниматься тем, что будем подставлять линейные операторы в многочлены.
Это своего рода инструмент для изучения линейных операторов.

В пределах этого параграфа мы зафиксируем линейный оператор $\A \in \End V$, где $V$ это конечномерное линейное пространство над полем $K$.

\vspace*{3mm}

\begin{conj} (Подстановка оператора в многочлен)

    Пусть $ f \in K[x], f = a_m x^m + \dots + a_1x + a_0$.
    Тогда подстановка оператора $\A$ в многочлен $f$ это выражение вида
    \[ f(\A) = a_m \A^m + \dots + a_1\A + a_0 \mathcal{E}_V \in \End V \quad (\A^i \text{--- композиция \,}  i \text{\, операторов} ) \]
\end{conj}

\begin{theorem} Свойства подстановки оператора в многочлен.

    Пусть $f, g \in K[x]$. Тогда:
    \begin{enumerate}
        \item $ (fg)(\A) = f(\A) g(\A)$.
        \item $ f(\A) g(\A) = g(\A) f(\A)$.
        \item $ \Ker f(\A) , \Imm f(\A)$  ---  $\A $-инвариантные подпространства.
    \end{enumerate}
    \begin{proof} \quad
    
    \begin{enumerate}
        \item Очевидно из перемножения многочленов.
        \item Следует из первого через $fg = gf$ (ведь многочлены всегда коммутируют).
        \item Сперва про ядро. Пусть $v \in \Ker f(\A)$ и надо доказать, что $\A v \in \Ker f(a)$.
        Введем $g(x) = x$. Тогда: \begin{gather*}
            \A v = g(\A) (v) \\
            \Rightarrow f(\A) (\A v) = f(\A) g(\A) (v) = g(\A) \cdot \underbrace{f(\A) (v)}_{\text{$ 0 $}} = 0 \Longrightarrow \A v \in \Ker f(\A)
        \end{gather*}
        
        Теперь про образ. Пусть $v \in \Imm f(\A)$ и надо доказать, что $\A v \in \Imm f(\A)$.
        Введем $g(x) = x$. Тогда: \begin{gather*}
            v \in \Imm f(\A) \Longleftrightarrow v = f(\A) (w) \\
            \Rightarrow \A v = g(\A) f(\A) (w) = f(\A) g(\A) (w) \in \Imm f(\A)
        \end{gather*}
    \end{enumerate}
    \end{proof}
\end{theorem}

Вспомним, что кольцо многочленов является евклидовым кольцом, что в свою очередь является областью главных идеалов (т.е. любой идеал евклидова кольца порождён одним элементом). 
Этот факт уже доказывался в первом семестре, но Жуков решил повторить доказательство. 

\begin{lemma}
    В евклидовом кольце любой идеал главный.

    \begin{proof}
    Пусть $R$ -- евклидово кольцо, $I \subset R$ его идеал (т.е. это подгруппа, а также $\forall b \in R$ выполняется $bI \subset I$) и $\nu$ -- евклидова норма.
    
    \quad Случай $I = 0$ тривиален, так как тогда $I = (0)$.

    \quad Пусть теперь $I \neq 0$. 
    Зафиксируем элемент $a \in I$, у которого евклидова норма минимальна (она принимает целые неотрицательные значения, поэтому такой точно найдется).
    Докажем, что $I = (a)$. Пусть $ b \in I$. Поделим на $a$ с остатком:
    \begin{gather*}
        b = aq + r, \quad \text{ где } \nu(r) < \nu(a) \text{ или } r = 0
    \end{gather*}
    \quad Первый случай невозможен, так как $ \nu(a) $ минимальна. 
    Значит, остаток равен нулю, тогда $b = aq$, т.е. $b \in (a)$.
    \end{proof}
\end{lemma}

\vspace*{3mm}

Этот факт мы сейчас будем использовать.

\vspace*{3mm}

\begin{conj} 
    Будем называть $f \in K[x]$ аннулятором (аннулирующим многочленом) $\A$, если $f(\A) = 0$.
\end{conj}

\vspace*{3mm}

\begin{theorem}
    Множество аннуляторов оператора -- главный идеал в $K[x]$.
\end{theorem}
\begin{proof}
    Очевидно, что свойства группы выполняются, поэтому осталось только доказать, что это идеал.
    Пусть $ f \in I$. Тогда:
    \[ \forall g \in K[x]: \, (gf)(\A) = g(\A) \underbrace{f(\A)}_{0} = 0 \Longrightarrow gf \in I \]
    \quad Этот идеал главный, так как $K[x]$ евклидово кольцо.
\end{proof}

Раз идеал главный, логично было бы как-то выделить его образующий.

\vspace*{3mm}

\begin{conj}
    Пусть $\A \in \End V$, $ I = \{ f \,  |  \, f$ --- аннулятор $\A \} = (\mu_{\A})$.
    Тогда $\mu_{\A}$ --- минимальный многочлен оператора $\A$.
\end{conj}

\vspace*{3mm}

\notice Порождающий элемент главного идеала определён с точностью до ассоциированности, поэтому минимальный многочлен не единственнен.
Но зато это дает нам право считать, что он унитарный (старший коэффициент 1).


\notice А вдруг это нулевой идеал? О каком унитарном многочлене вообще тогда речь? 
Такого быть не может! Дело в том, что операторы образуют конечномерное пространство: $\dim \End V = n^2$, где $n = \dim V$.
Тогда \begin{gather*}
    \{ \mathcal{E}, \A, \A^2, \dots, \A^{n^2} \} - \text{ ЛЗС (т.к. мы перечислили $n^2 + 1$ элемент нашего пространства)} \\
    \Longrightarrow \, \exists \alpha_0, \alpha_1, \dots, \alpha_{n^2} \text{ не все 0 } : \alpha_0 \mathcal{E} + \alpha_1 \A \dots + \alpha_{n^2} \A^{n^2} = 0 \\
    \Longrightarrow f = \alpha_0 + \alpha_1 x + \dots + \alpha_{n^2} x \text{--- ненулевой аннулятор $\A$}
\end{gather*}

\begin{conj}
    Пусть $v \in V, \A \in \End V$.
    Говорят, что $f \in K[x]$ -- аннулятор вектора $v$ (по отношению к оператору $\A$), если $f(\A) (v) = 0$.
\end{conj}

По аналогии с аннулятором оператора можно ввести понятие минимального аннулятора вектора.
Действительно, то, что множество аннуляторов вектора это главный идеал в $K[x]$, доказывается аналогично.
Выделив образующий, получаем минимальный аннулятор вектора.

\begin{conj}
    Пусть $I_v = \{ f \, | \, f(\A) (v) = 0 \} = (\mu_{\A, v})$.
    Тогда $\mu_{\A, v}$ -- минимальный аннулятор $v$ (по отношению к $\A$).
\end{conj}

Очевидно, что любой аннулятор оператора также является аннулятором любого вектора.
Из этого в частности следует, что $I_v \neq 0$ и $\mu_{\A, v} \neq 0$. 

\subsection{Циклические подпространства}

\begin{conj}
    Пусть $v \in V$.
    Тогда циклическое подпространство -- это минимальное подпространство $V$, содержащее $v$ и инвариантное относительно $\A$.
    Обозначается как $L_v$ и по определению равно $\Lin (v, \A v, \A^2 v, \dots)$.
\end{conj}

\vspace*{3mm}

Несмотря на то, что это линейная оболочка бесконечного количества векторов, это подпространство конечномерного $V$, поэтому можно выделить базис.

\vspace*{2mm}

\begin{theorem}
    Пусть $d = \deg \mu_{\A, v}$.
    Тогда $\{ v, \A v, \A^2 v, \dots, \A^{d - 1} v \}$ -- базис $L_v$.
\end{theorem}

\begin{proof}
    Докажем линейную независимость.
    Предположим, что $v, \A v, \A^2 v, \dots, \A^{d - 1} v $ -- ЛЗС:
    \[ \exists \beta_0, \dots, \beta_{d-1} : \;\; \beta_0 v + \dots + \beta_{d - 1} \A^{d - 1} v = 0 \]
    \quad Составим многочлен $f = \beta_0 + \beta_1 x + \dots + \beta_{d - 1} x^{d - 1}$. 
    Тогда: \[ f(\A)(v) = 0 \Longrightarrow \mu_{\A, v} | f \Longrightarrow f = 0 \Longrightarrow \beta_0 = \dots = \beta_{d - 1} = 0 \]
    \quad Второй переход верен, так как $\deg \mu_{\A, v} = d$, а $\deg f = d - 1$.
    
    \quad Теперь докажем, что последующие степени нам не интересны, так как они выражаются через первые $d$ штук.
    Пусть $W = \Lin (v, \A v, \dots, \A^{d - 1} v)$. 
    Докажем, что $\forall m \geqslant d$ выполняется $\A^m v \in W$.
    Будем доказывать по индукции: \begin{itemize}
        \item База $m = d$. Пусть минимальный аннулятор $v$ имеет вид: \[ \mu_{\A, v} = x^d + \alpha_{d - 1} x^{d - 1} + \dots + \alpha_0 \]
        Тогда: \begin{gather*}
            \mu_{\A, v}(\A)(v) = \A^dv + \alpha_{d - 1} \A^{d - 1}v + \dots + \alpha_1 \A v + \alpha_1 v = 0 \\
            \Longrightarrow \A^d v = - \alpha_{d - 1} \A^{d - 1}v - \dots - \alpha_0 v \in W
        \end{gather*}
        \item Переход $k \to k + 1$.  
        По индукционному предположению: \[ \A^k v = \alpha_0 v + \dots + \alpha_{d - 1} \A^{d - 1}v \]
        Применим к левой и правой части оператор $\A$: \[ \A^{k+1}v = \underbrace{\alpha_0\A v + \dots}_{\in W} + \underbrace{\alpha_{d-1}\A^d v}_{\in W} \Longrightarrow \A^{k+1}v \in W \]
    \end{itemize}
    \quad Таким образом, $L_v = W$.
\end{proof}

\vspace*{5mm}

Поймем, как устроена матрица индуцированного на $L_v$ оператора $\A$.
Зафиксируем базис $E = \{ v, \A v, \A^2 v, \dots, \A^{d-1} v \}$.
Тогда: \[ [\A |_{L_{v}}]_E = 
\left(\begin{array}{ccccc}
    0 & 0 & \dots & 0 & -\alpha_0 \\ 
    1 & 0 & \dots & 0 & -\alpha_1 \\ 
    0 & 1 & \dots & 0 & -\alpha_2 \\ 
    \vdots & \vdots & \vdots & \vdots & \vdots \\ 
    0 & 0 & 0 & 1 & -\alpha_{d - 1}
\end{array}\right) - \text{ сопровождающая матрица многочлена $\mu_{\A, v}$.} \]
Действительно, первый вектор переходит во второй, второй в третий и т.д. При применении оператора к последнему появляются те самые коэффициенты из доказательства. 

Матрица называется сопровождающей матрицей многочлена $\mu_{\A, v}$, так как он полностью определяет ее.

\vspace*{3mm}

\begin{lemma}
    Характеристический многочлен индуцированного оператора с точностью до знака равен соответствующему минимальному многочлену:
    \[ \chi_{\A |_{L_v}} = \pm \mu_{\A, v} \]
\end{lemma}
\begin{proof}
    \[ \chi_{\A |_{L_v}} = \begin{vmatrix*}
        -x & 0 & \dots & 0 & -\alpha_0 \\ 
        1 & -x & \dots & 0 & -\alpha_1 \\ 
        0 & 1 & \dots & 0 & -\alpha_2 \\ 
        \vdots & \vdots & \vdots & \vdots & \vdots \\ 
        0 & 0 & 0 & 1 & -\alpha_{d - 1} - x
    \end{vmatrix*} \]

    Воспользуемся разложением по последнему столбцу.
    Для этого надо просуммировать следующие слагаемые: \begin{itemize}
        \item $(-\alpha_0) \cdot (-1)^{d+1} \cdot \begin{vmatrix}
            1 & 0 & \dots & 0 \\
            0 & 1 & \dots & 0 \\
            0 & 0 & \ddots & 0 \\
            0 & 0 & \dots & 1 
        \end{vmatrix} = (-1)^d \alpha_0$  
        \item $(-\alpha_1) \cdot (-1)^{d+2} \cdot \begin{vmatrix}
            -x & 0 & \dots & 0 \\
            0 & 1 & \dots & 0 \\
            0 & 0 & \ddots & 0 \\
            0 & 0 & \dots & 1 
        \end{vmatrix} = (-1)^d \alpha_1 x$
        \item \dots
        \item $(-\alpha_{d-1} - x) \cdot (-1)^{d+d} \cdot \begin{vmatrix}
            -x & 0 & \dots & 0 \\
            0 & -x & \dots & 0 \\
            0 & 0 & \ddots & 0 \\
            0 & 0 & \dots & -x 
        \end{vmatrix} = (-1)^d (\alpha_{d-1}x^{d-1} + x^d)$
    \end{itemize}
    Таким образом: \[ \chi_{\A |_{L_v}} = (-1)^d(\alpha_0 + \alpha_1 x + \dots + \alpha_{d - 1}x^{d-1} + x^d) = \pm \mu_{\A, v}  \]
\end{proof}

Этот лемма нужна нам для того, чтобы доказать важную теорему.

\vspace*{3mm}

\textbf{Теорема Гамильтона-Кэли.} 

\quad\quad Характеристический многочлен оператора -- его аннулятор: \[ \chi_A(\A) = 0 \]

\begin{proof}
    Пусть $v \in V$.
    В самом начале разговора о характеристических многочленах было доказано, что если $W$ инвариантное подпространство, то $\chi_{\A|_W}$ делит $\chi_\A$.
    $L_v$ -- инвариантное подпространство, поэтому $\chi_{\A|_{L_v}} | \chi_\A$. 
    Воспользовавшись леммой, заключаем, что $\mu_{\A, v} | \chi_\A$, а значит $\chi_\A(\A)(v) = 0$.
    Это выполняется для всех $v$, следовательно, $\chi_A$ -- аннулятор $\A$.
\end{proof}

\vspace*{3mm}

\follow Минимальный многочлен оператора делит его характеристический: \[ \mu_{\A} | \chi_{\A} \]
\begin{proof}
    Аннуляторы оператора являются главным идеалом, поэтому любой аннулятор делится на минимальный.
\end{proof}

\vspace*{3mm}

Разберем простой пример.

\begin{example}
    Пусть $[\A]_E = \left(\begin{array}{cc}
        \lambda_1 & 0 \\ 
        0 & \lambda_2
        \end{array}\right)$.
        Тогда: \[ \chi_{\A} = (x - \lambda_1)(x - \lambda_2) \]
        Очевидно, что $\mu_{\A, e_1} = x - \lambda_1$, $\mu_{\A, e_2} = x - \lambda_2$.
        Рассмотрим 2 случая:
        \begin{itemize}
            \item $ \lambda_1 \neq \lambda_2 \Longrightarrow \mu_{\A} = (x - \lambda_1) (x - \lambda_2) = \chi_\A$.
            \item $ \lambda_1 = \lambda_2 \Longrightarrow \mu_{\A} = x - \lambda_1 \neq \chi_\A$.
        \end{itemize} 
\end{example}


\subsection{Разложение подпространства в прямую сумму примарных подпространств}

\begin{conj}
    Вектор $v \in V$ называется $p$-примарным, если $\mu_{\A, v} = p^t$, где $p \in K[x]$ неприводимый и $t \geqslant 0$.
\end{conj}

\notice Случай, когда $t = 0$ тривиален, так как тогда $v = 0$.

\vspace*{3mm}

\begin{lemma}
    Все $p$-примарные векторы образуют инвариантное подпространство: \[ W_p = \{ v \in V \, | \, v - \text{ $p$-примарный}  \} - \text{инвариантное подпространство } V \]
\end{lemma}
\begin{proof} \quad

    \begin{itemize}
        \item Замкнутость по сложению: \begin{gather*}
            w_1, w_2 \in W_p \Rightarrow p^{t_1}(\A)(w_1) = 0 \, \text{ и } \,  p^{t_2}(\A)(w_2) = 0 \\
            \Longrightarrow p^t(\A)(w_1 + w_2) = p^t(\A)(w_1) + p^t(\A)(w_2) = 0, \quad \text{где } t = \max(t_1, t_2) \\
            \Longrightarrow \mu_{\A, w_1 + w_2} \, | \, p^t \Longrightarrow (w_1 + w_2) \in W_p
        \end{gather*}
        \item Умножение на скаляр: \[ \mu_{\A, w} = \mu_{\A, \lambda w} \, \text{ по определению } \]
        \item Инвариантность: \begin{gather*}
            W_p = \bigcup_{t \geqslant 0} \Ker p^t(\A) \\
            \forall t \geqslant 0 \;\; \Ker p^t(\A) - \text{ $\A$-инвариантно } \Longrightarrow W_p - \text{ $\A$-инвариантно }
        \end{gather*}
        Вообще говоря, мы рассматриваем объединение конечномерных, вложенных друг в друга подпространств, поэтому оно конечно и равно $\Ker p^N(\A)$ при достаточно большом $N$.
    \end{itemize}    
\end{proof}

\begin{conj}
    Векторное пространство $V$ называется $p$-примарным (относительно $\A$), если $V = W_p$.
\end{conj}

\vspace*{3mm}
Докажем техническую лемму, которая понадобится нам при доказательстве последующей теоремы.

\begin{lemma}
    Пусть $\mu_{\A} = fg$, причем $(f, g) = 1$.
    Тогда: \begin{gather*}
        V = V_1 \oplus V_2, \; \text{ где } V_1, V_2 - \text{ $\A$-инвариантны} \\
        \mu_{\A |_{V_1}} \, | \, f \, \text{ и } \,  \mu_{\A |_{V_2}} \, | \, g
    \end{gather*}
\end{lemma}
\begin{proof}
    Пусть $ V_1 := \Ker f(\A), V_2 := \Ker g(\A)$ -- инвариантные подпространства.
    Докажем, что они подходят.
    \begin{itemize}
        \item Поймём, что $V_1 + V_2 = V$. 
        Воспользуемся тем, что многочлены взаимно просты: \[ (f, g) = 1 \Longrightarrow fa + gb = 1, \quad a, b \in K[x] \]
        Теперь возьмем произвольный вектор из $V$ и разложим его в сумму: \[ \forall v \in V \;\; v = \mathcal{E}(v) = (f(\A)a(\A) + g(\A)b(\A))(v) = f(a(\A)(v)) + g(b(\A)(v)) \]
        Осталось заметить, что $f(\A)g(\A) = g(\A)f(\A) = \mu_\A(\A) = 0$ по условию. 
        Поэтому, если мы действуем оператором $g(\A)$ на $v$, то обязаны попасть в ядро $f(\A)$, и наоборот.
        Таким образом: \[ \begin{cases}
            f(a(\A)(v)) \in \Ker g(\A) = V_2 \\
            g(b(\A)(v)) \in \Ker f(\A) = V_1
        \end{cases} \]
        Получается, что разложили любой вектор $v$ в сумму двух из $V_1$ и $V_2$.

        \item Поймем, что $V_1 \cap V_2 = 0$.
        Возьмем $v \in V_1 \cap V_2$: \begin{gather*}
            \begin{cases}
                v \in V_1 = \Ker f(\A) \Rightarrow f(\A)(v) = 0 \Rightarrow \mu_{\A, v} | f \\
                v \in V_2 = \Ker g(\A) \Rightarrow g(\A)(v) = 0 \Rightarrow \mu_{\A, v} | g
            \end{cases}
        \end{gather*}
        Но $(f, g) = 1$ по условию $\Longrightarrow \mu_{\A, v} = 1 \Longrightarrow v = 0$.
        
        \item Поймем, что $ \mu_{\A |_{V_1}} \, | \, f$ и $\mu_{\A |_{V_2}} \, | \, g$.
        На самом деле мы это выяснили еще в предыдущем пункте.
        Для любого $v \in V_1$ выполняется $\mu_{\A, v} | f$, следовательно $f$ -- аннулятор всех $v$ из $V_1$, т.е. $ \mu_{\A |_{V_1}} \, | \, f$. 
        Для $V_2$ и $g$ аналогично.
    \end{itemize}
\end{proof} 